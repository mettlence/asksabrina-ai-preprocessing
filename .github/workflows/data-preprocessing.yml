name: AI Insights Preprocessing

on:
  schedule:
    # Run every 6 hours (at 00:00, 06:00, 12:00, 18:00 UTC)
    - cron: '0 */6 * * *'
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      lookback_hours:
        description: 'Hours to look back for orders'
        required: false
        default: '720'

jobs:
  preprocess:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Setup SSH key for EC2 tunnel
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_KEY }}" > ~/.ssh/ec2_key.pem
          chmod 600 ~/.ssh/ec2_key.pem
          ssh-keyscan -H ${{ secrets.EC2_HOST }} >> ~/.ssh/known_hosts
      
      - name: Start SSH tunnel to EC2 MongoDB
        run: |
          ssh -i ~/.ssh/ec2_key.pem -f -N -L 27017:localhost:27017 ubuntu@${{ secrets.EC2_HOST }}
          sleep 5
          echo "SSH tunnel established"
      
      - name: Run preprocessing
        env:
          MONGODB_SOURCE_URI: ${{ secrets.MONGODB_SOURCE_URI }}
          MONGODB_TARGET_URI: mongodb://${{ secrets.MONGO_USERNAME }}:${{ secrets.MONGO_PASSWORD }}@localhost:27017/?authSource=admin
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          LOOKBACK_HOURS: ${{ github.event.inputs.lookback_hours || '720' }}
          BATCH_SIZE: '50'
          MAX_WORKERS: '5'
        run: |
          python preprocess.py
      
      - name: Cleanup SSH tunnel
        if: always()
        run: |
          pkill -f "ssh.*27017:localhost:27017" || true
          rm -f ~/.ssh/ec2_key.pem
      
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: preprocessing-logs-${{ github.run_number }}
          path: preprocess.log
          retention-days: 7
      
      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const issue_body = `
            ## ⚠️ Preprocessing Pipeline Failed
            
            **Run**: [#${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            **Time**: ${new Date().toISOString()}
            
            Please check the logs for details.
            `;
            
            // Optional: Create issue or send notification
            console.log(issue_body);

  health-check:
    runs-on: ubuntu-latest
    needs: preprocess
    if: success()
    
    steps:
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install pymongo
        run: |
          pip install pymongo

      - name: Setup SSH key for EC2 tunnel
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_KEY }}" > ~/.ssh/ec2_key.pem
          chmod 600 ~/.ssh/ec2_key.pem
          ssh-keyscan -H ${{ secrets.EC2_HOST }} >> ~/.ssh/known_hosts

      - name: Start SSH tunnel to EC2 MongoDB
        run: |
          ssh -i ~/.ssh/ec2_key.pem -f -N -L 27017:localhost:27017 ubuntu@${{ secrets.EC2_HOST }}
          sleep 5

      - name: Verify processing
        env:
          MONGODB_TARGET_URI: mongodb://${{ secrets.MONGO_USERNAME }}:${{ secrets.MONGO_PASSWORD }}@localhost:27017/?authSource=admin
        run: |
          python -c "
          from pymongo import MongoClient
          import os
          from datetime import datetime, timedelta
          
          client = MongoClient(os.environ['MONGODB_TARGET_URI'])
          db = client['asksabrina']
          
          recent = db.ai_insight.count_documents({
            'processed_at': {'\$gte': datetime.utcnow() - timedelta(hours=1)}
          })
          print(f'Recently processed records: {recent}')
          
          total_24h = db.ai_insight.count_documents({
            'processed_at': {'\$gte': datetime.utcnow() - timedelta(hours=24)}
          })
          print(f'Total processed in last 24h: {total_24h}')
          
          client.close()
          "

      - name: Cleanup SSH tunnel
        if: always()
        run: |
          pkill -f "ssh.*27017:localhost:27017" || true
          rm -f ~/.ssh/ec2_key.pem